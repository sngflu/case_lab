{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9936041,"sourceType":"datasetVersion","datasetId":6108360}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Установка библиотек и импорты","metadata":{}},{"cell_type":"markdown","source":"Удаляем albumentations и ultralytics для предотвращения ошибки.","metadata":{}},{"cell_type":"code","source":"!pip uninstall ultralytics\n!pip uninstall albumentations -y","metadata":{"execution":{"iopub.status.busy":"2024-11-20T16:59:20.717368Z","iopub.execute_input":"2024-11-20T16:59:20.718146Z","iopub.status.idle":"2024-11-20T16:59:25.312410Z","shell.execute_reply.started":"2024-11-20T16:59:20.718083Z","shell.execute_reply":"2024-11-20T16:59:25.310906Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Удаляем папки, созданные в предыдущих запусках","metadata":{}},{"cell_type":"code","source":"# !rm -rf \"/kaggle/working/DocLayout YOLO\"\n# !rm -rf /kaggle/working/wandb\n# !rm -rf /kaggle/working/config","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:21:05.060673Z","iopub.execute_input":"2024-11-20T17:21:05.061359Z","iopub.status.idle":"2024-11-20T17:21:10.455236Z","shell.execute_reply.started":"2024-11-20T17:21:05.061303Z","shell.execute_reply":"2024-11-20T17:21:10.453208Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Скачиваем библиотеки для работы DocLayout-YOLO","metadata":{}},{"cell_type":"code","source":"!pip install doclayout_yolo\n!pip install huggingface_hub","metadata":{"execution":{"iopub.status.busy":"2024-11-20T16:59:28.914605Z","iopub.execute_input":"2024-11-20T16:59:28.915033Z","iopub.status.idle":"2024-11-20T16:59:51.586438Z","shell.execute_reply.started":"2024-11-20T16:59:28.914995Z","shell.execute_reply":"2024-11-20T16:59:51.585129Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Пишем стандартные импорты","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport torch\nfrom pathlib import Path\nfrom doclayout_yolo import YOLOv10\nfrom huggingface_hub import hf_hub_download\nimport json\nimport shutil\nimport cv2\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pass\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-20T16:59:51.588485Z","iopub.execute_input":"2024-11-20T16:59:51.588917Z","iopub.status.idle":"2024-11-20T17:00:20.791492Z","shell.execute_reply.started":"2024-11-20T16:59:51.588875Z","shell.execute_reply":"2024-11-20T17:00:20.790066Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Настраиваем wandb","metadata":{}},{"cell_type":"code","source":"!pip install wandb --q\n\nimport wandb\n\nsecret_value = 'тут ключ от wandbai'\n\nwandb.login(key=secret_value)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:00:20.795252Z","iopub.execute_input":"2024-11-20T17:00:20.795743Z","iopub.status.idle":"2024-11-20T17:00:31.365200Z","shell.execute_reply.started":"2024-11-20T17:00:20.795703Z","shell.execute_reply":"2024-11-20T17:00:31.363827Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Подготовка датасета","metadata":{}},{"cell_type":"markdown","source":"Создаём необходимые репозитории:","metadata":{}},{"cell_type":"code","source":"!mkdir /kaggle/working/datasets","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:00:31.367351Z","iopub.execute_input":"2024-11-20T17:00:31.367718Z","iopub.status.idle":"2024-11-20T17:00:31.375865Z","shell.execute_reply.started":"2024-11-20T17:00:31.367684Z","shell.execute_reply":"2024-11-20T17:00:31.374424Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir /kaggle/working/datasets/prepared_data","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:00:31.378095Z","iopub.execute_input":"2024-11-20T17:00:31.378667Z","iopub.status.idle":"2024-11-20T17:00:31.390610Z","shell.execute_reply.started":"2024-11-20T17:00:31.378592Z","shell.execute_reply":"2024-11-20T17:00:31.389457Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir /kaggle/working/config","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:00:31.392806Z","iopub.execute_input":"2024-11-20T17:00:31.393373Z","iopub.status.idle":"2024-11-20T17:00:32.586515Z","shell.execute_reply.started":"2024-11-20T17:00:31.393318Z","shell.execute_reply":"2024-11-20T17:00:32.583981Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Переводим датасет в YOLO формат","metadata":{}},{"cell_type":"code","source":"def convert_to_yolo_format(bbox, img_width, img_height):\n    \"\"\"Конвертация координат из абсолютных в относительные для YOLO\"\"\"\n    x_center = (bbox[0] + bbox[2]) / 2 / img_width\n    y_center = (bbox[1] + bbox[3]) / 2 / img_height\n    width = (bbox[2] - bbox[0]) / img_width\n    height = (bbox[3] - bbox[1]) / img_height\n    return [x_center, y_center, width, height]\n\ndef prepare_dataset():\n    \"\"\"Подготовка датасета\"\"\"\n    raw_data_dir = Path('/kaggle/input/doclayout-raw-data/raw_data')\n    output_dir = Path('/kaggle/working/datasets/prepared_data')\n    \n    print(f\"Проверка директорий:\")\n    print(f\"raw_data_dir: {raw_data_dir}\")\n    print(f\"output_dir: {output_dir}\")\n\n    # проверяем существование директорий\n    if not (raw_data_dir / \"images\").exists():\n        raise ValueError(f\"Директория с изображениями не найдена: {raw_data_dir / 'images'}\")\n    if not (raw_data_dir / \"jsons\").exists():\n        raise ValueError(f\"Директория с JSON файлами не найдена: {raw_data_dir / 'jsons'}\")\n\n    # создаем необходимые директории\n    images_dir = output_dir / \"images\"\n    labels_dir = output_dir / \"labels\"\n    images_dir.mkdir(parents=True, exist_ok=True)\n    labels_dir.mkdir(parents=True, exist_ok=True)\n\n    # словарь для маппинга классов\n    class_map = {\n        \"title\": 0, \"paragraph\": 1, \"table\": 2, \"picture\": 3,\n        \"table_signature\": 4, \"picture_signature\": 5, \"numbered_list\": 6,\n        \"marked_list\": 7, \"header\": 8, \"footer\": 9, \"footnote\": 10,\n        \"formula\": 11\n    }\n\n    # собираем пары файлов\n    valid_pairs = []\n    image_files = list(Path(raw_data_dir / \"images\").glob(\"*.png\"))\n    print(f\"\\nНайдено {len(image_files)} PNG файлов\")\n    \n    cnt = 0\n    for img_path in image_files:\n        json_path = raw_data_dir / \"jsons\" / f\"{img_path.stem}.json\"\n#         print(f\"\\nОбработка файла: {img_path.name}\")\n#         print(f\"Поиск JSON: {json_path}\")\n        \n        if not json_path.exists():\n            print(f\"Пропускаем {img_path.name}: нет соответствующего JSON файла\")\n            continue\n\n        try:\n            # проверяем, что изображение читается\n            img = cv2.imread(str(img_path))\n            if img is None:\n                print(f\"Пропускаем {img_path.name}: невозможно прочитать изображение\")\n                continue\n\n            # копируем изображение\n            new_img_path = images_dir / img_path.name\n            shutil.copy(str(img_path), str(new_img_path))\n#             print(f\"Изображение скопировано в {new_img_path}\")\n\n            # читаем JSON\n            with open(json_path, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n\n            # создаем YOLO-формат аннотаций\n            label_content = []\n            img_width = data['image_width']\n            img_height = data['image_height']\n\n            for class_name, boxes in data.items():\n                if class_name in class_map and isinstance(boxes, list) and boxes:\n                    class_id = class_map[class_name]\n                    for bbox in boxes:\n                        yolo_bbox = convert_to_yolo_format(bbox, img_width, img_height)\n                        label_content.append(f\"{class_id} {' '.join(map(str, yolo_bbox))}\")\n\n            # сохраняем файл с аннотациями\n            label_file = labels_dir / f\"{img_path.stem}.txt\"\n            with open(label_file, 'w') as f:\n                f.write('\\n'.join(label_content))\n#             print(f\"Создан файл аннотаций: {label_file}\")\n\n            valid_pairs.append(img_path.stem)\n#             print(f\"Пара успешно обработана\")\n            cnt += 1\n            if cnt % 100 == 0:\n                print(f\"Обработано {cnt} файлов\")\n            \n        except Exception as e:\n            print(f\"Ошибка при обработке {img_path.name}: {str(e)}\")\n            continue\n\n    print(f\"\\nИтоги обработки:\")\n    print(f\"Всего найдено изображений: {len(image_files)}\")\n    print(f\"Успешно обработано пар: {len(valid_pairs)}\")\n\n    if not valid_pairs:\n        raise ValueError(\"Не найдено валидных пар изображение-разметка!\")\n\n    # создаем train/val split (80/20)\n    np.random.shuffle(valid_pairs)\n    split_idx = int(len(valid_pairs) * 0.8)\n    train_pairs = valid_pairs[:split_idx]\n    val_pairs = valid_pairs[split_idx:]\n\n    # сохраняем списки train/val с полными путями\n    with open(output_dir / \"train.txt\", 'w') as f:\n        f.write('\\n'.join(str(images_dir / f\"{name}.png\") for name in train_pairs))\n    \n    with open(output_dir / \"val.txt\", 'w') as f:\n        f.write('\\n'.join(str(images_dir / f\"{name}.png\") for name in val_pairs))\n\n    print(f\"\\nСоздание файлов со списками:\")\n    print(f\"train.txt: {len(train_pairs)} образцов\")\n    print(f\"val.txt: {len(val_pairs)} образцов\")\n    \n    return len(valid_pairs)\n\ndef main():\n    # подготовка данных\n    print(\"Подготовка данных...\")\n    num_samples = prepare_dataset()\n    output_dir = Path('/kaggle/working/datasets/prepared_data')\n\n    # создаем конфигурационный файл\n    config_dir = Path('/kaggle/working/config')\n    config_dir.mkdir(exist_ok=True)\n    \n    config_content = f\"\"\"\npath: {str(output_dir)}\ntrain: {str(output_dir / 'train.txt')}\nval: {str(output_dir / 'val.txt')}\n\nnc: 12\nnames: ['title', 'paragraph', 'table', 'picture', 'table_signature', 'picture_signature', \n        'numbered_list', 'marked_list', 'header', 'footer', 'footnote', 'formula']\n\"\"\"\n    \n    config_path = config_dir / \"doclayout.yaml\"\n    with open(config_path, 'w') as f:\n        f.write(config_content)\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:00:32.589517Z","iopub.execute_input":"2024-11-20T17:00:32.590032Z","iopub.status.idle":"2024-11-20T17:00:32.606224Z","shell.execute_reply.started":"2024-11-20T17:00:32.589988Z","shell.execute_reply":"2024-11-20T17:00:32.604499Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Обучение модели","metadata":{}},{"cell_type":"markdown","source":"Ещё кое-какие установки для исключения ошибок:","metadata":{}},{"cell_type":"code","source":"!pip install -U ipywidgets -q\n!pip uninstall ray[tune] -y -q","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:00:32.608146Z","iopub.execute_input":"2024-11-20T17:00:32.608595Z","iopub.status.idle":"2024-11-20T17:00:46.129687Z","shell.execute_reply.started":"2024-11-20T17:00:32.608543Z","shell.execute_reply":"2024-11-20T17:00:46.127983Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install doclayout_yolo -q","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:00:46.132493Z","iopub.execute_input":"2024-11-20T17:00:46.132911Z","iopub.status.idle":"2024-11-20T17:00:56.919678Z","shell.execute_reply.started":"2024-11-20T17:00:46.132874Z","shell.execute_reply":"2024-11-20T17:00:56.918030Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Обучение модели на GPU","metadata":{}},{"cell_type":"markdown","source":"Основной код обучения модели:","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nfrom pathlib import Path\nfrom doclayout_yolo import YOLOv10\nfrom huggingface_hub import hf_hub_download\nimport wandb\nimport yaml\nfrom datetime import datetime\nimport torch\n\ndef setup_wandb(config_path):\n    \"\"\"Настройка Weights & Biases\"\"\"\n    with open(config_path) as f:\n        data_config = yaml.safe_load(f)\n    wandb.init(\n        project=\"DocLayout-YOLO-Training\",\n        name=f\"run_{datetime.now().strftime('%Y%m%d_%H%M')}\",\n        config={\n            \"architecture\": \"YOLOv10\",\n            \"dataset_size\": 16000,\n            \"batch_size\": 4,\n            \"learning_rate\": 0.001,\n            \"epochs\": 12,\n            \"image_size\": 800,\n            \"classes\": data_config['names']\n        }\n    )\n\ndef cleanup_gpu_memory():\n    \"\"\"Базовая очистка памяти GPU\"\"\"\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\ndef main():\n    cleanup_gpu_memory()\n    if torch.cuda.is_available():\n        torch.cuda.set_per_process_memory_fraction(0.9)\n\n    # определение путей\n    project_root = Path('/kaggle/working')\n    raw_data_dir = Path('/kaggle/input/doclayout-raw-data/raw_data')\n    output_dir = Path('/kaggle/working/datasets/prepared_data')\n\n    # создание конфигурационного файла\n    config_dir = Path('/kaggle/working/config')\n    config_dir.mkdir(exist_ok=True)\n    config_content = f\"\"\"\npath: {str(output_dir)}\ntrain: {str(output_dir / 'train.txt')}\nval: {str(output_dir / 'val.txt')}\nnc: 12\nnames: ['title', 'paragraph', 'table', 'picture', 'table_signature', \n        'picture_signature', 'numbered_list', 'marked_list', 'header', \n        'footer', 'footnote', 'formula']\n\"\"\"\n    config_path = config_dir / \"doclayout.yaml\"\n    with open(config_path, 'w') as f:\n        f.write(config_content)\n\n    setup_wandb(config_path)\n\n    print(\"Загрузка предобученной модели...\")\n    try:\n        model_path = hf_hub_download(\n            repo_id=\"juliozhao/DocLayout-YOLO-DocStructBench\",\n            filename=\"doclayout_yolo_docstructbench_imgsz1024.pt\"\n        )\n    except Exception as e:\n        print(f\"Ошибка загрузки модели: {e}\")\n        return\n\n    model = YOLOv10(model_path)\n\n    print(\"Запуск обучения...\")\n    results = model.train(\n        data=str(config_path),\n        epochs=12,\n        imgsz=800,\n        batch=4,\n        workers=4,\n        project='DocLayout YOLO',\n        name=\"experiment3\",\n        exist_ok=True,\n        cache=False,\n        pretrained=True,\n        resume=False,\n        verbose=True,\n        amp=False, \n        optimizer=\"Adam\",\n        lr0=0.001,\n        lrf=0.01,\n        momentum=0.935,\n        weight_decay=0.0005,\n        warmup_epochs=3.0,\n        warmup_momentum=0.8,\n        warmup_bias_lr=0.1,\n        box=7.5,\n        cls=0.5,\n        dfl=1.5,\n        plots=True,\n        save=True,\n        save_period=3,\n        multi_scale=False,\n        augment=True,\n        degrees=2.0,        \n        hsv_h=0.2,         \n        hsv_s=0.2,       \n        hsv_v=0.2,        \n        mosaic=0.0,      \n        flipud=0.0,         \n        fliplr=0.0,         \n        patience=10,\n        overlap_mask=False\n    )\n    \n    if hasattr(results, 'results_dict'):\n        metrics = results.results_dict\n        print(\"\\nИтоговая статистика обучения:\")\n        if 'metrics/mAP50(B)' in metrics:\n            print(f\"Лучший mAP50: {max(metrics['metrics/mAP50(B)']):.4f}\")\n        if 'metrics/mAP50-95(B)' in metrics:\n            print(f\"Лучший mAP50-95: {max(metrics['metrics/mAP50-95(B)']):.4f}\")\n\n        wandb.run.summary['best_map50'] = max(metrics.get('metrics/mAP50(B)', [0]))\n        wandb.run.summary['best_map50_95'] = max(metrics.get('metrics/mAP50-95(B)', [0]))\n        wandb.finish()\n\n    print(f\"Обучение завершено. Модель сохранена в {project_root}/runs/train/exp/weights\")\n    return results\n\nif __name__ == \"__main__\":\n    try:\n        cleanup_gpu_memory()\n        \n        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'\n        \n        results = main()\n        print(\"Обучение успешно завершено\")\n    except Exception as e:\n        import traceback\n        print(f\"Произошла ошибка: {e}\")\n        print(\"Полный стек ошибки:\")\n        print(traceback.format_exc())\n    finally:\n        cleanup_gpu_memory()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:14:26.700113Z","iopub.execute_input":"2024-11-20T17:14:26.700707Z","iopub.status.idle":"2024-11-20T17:18:42.018997Z","shell.execute_reply.started":"2024-11-20T17:14:26.700664Z","shell.execute_reply":"2024-11-20T17:18:42.015749Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Результаты","metadata":{}},{"cell_type":"markdown","source":"В результате наша модель достигла довольно высоких метрик (их показатели лежат в одной папке с ноутбуком)\n\n---\n\nДля улучшения модели далее сконцентрируемся на следующем:\n* Попробуем преобразовать image_size для более точного соотношения сторон\n* Добавим метрики **IoU** и **F1 для IoU > 0,5**\n* Добавим метрики для отдельных классов\n* Будем анализировать эффективность модели в том числе с использованием confusion matrix\n* Попробуем использовать другие датасеты для значительного повышения обобщающей способности модели","metadata":{}}]}