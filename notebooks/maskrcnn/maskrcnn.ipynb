{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### при попытке обучить модель постоянно упиралась в ограничение по памяти, что не решалось изменением чего-либо. модель лишь раз прошла одну эпоху, но файл тогда сохранить не удалось по причине автоматического рестарта среды. эксперту об этом говорили, но все же решено хотя бы прикрепить ноутбук. изначально вера в данную архитектуру была сильной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## установка и импорт необходимых зависимостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T22:33:15.908890Z",
     "iopub.status.busy": "2024-11-24T22:33:15.908543Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install pycocotools --q\n",
    "!pip install torch torchvision --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T22:33:32.029309Z",
     "iopub.status.busy": "2024-11-24T22:33:32.029012Z",
     "iopub.status.idle": "2024-11-24T22:33:32.034427Z",
     "shell.execute_reply": "2024-11-24T22:33:32.033564Z",
     "shell.execute_reply.started": "2024-11-24T22:33:32.029281Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection import MaskRCNN\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## конвертирование исходного датасета в формат COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T22:27:22.017248Z",
     "iopub.status.busy": "2024-11-24T22:27:22.016778Z",
     "iopub.status.idle": "2024-11-24T22:27:22.026734Z",
     "shell.execute_reply": "2024-11-24T22:27:22.025894Z",
     "shell.execute_reply.started": "2024-11-24T22:27:22.017216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def convert_to_coco_format(json_folder, image_folder, output_path):\n",
    "    coco_format = {\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": []\n",
    "    }\n",
    "    category_mapping = {\n",
    "        \"table\": 1,\n",
    "        \"title\": 2,\n",
    "        \"paragraph\": 3,\n",
    "        \"formula\": 4,\n",
    "        \"header\": 5,\n",
    "        \"footer\": 6,\n",
    "        \"footnote\": 7,\n",
    "        \"numbered_list\": 8,\n",
    "        \"marked_list\": 9,\n",
    "        \"table_signature\": 10,\n",
    "        \"picture_signature\": 11,\n",
    "        \"picture\": 12\n",
    "    }\n",
    "    \n",
    "    coco_format[\"categories\"] = [{\"id\": v, \"name\": k} for k, v in category_mapping.items()]\n",
    "    \n",
    "    annotation_id = 1\n",
    "    for json_file in Path(json_folder).glob(\"*.json\"):\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        image_path = os.path.join(image_folder, os.path.basename(data[\"image_path\"]))\n",
    "        image_id = int(os.path.splitext(os.path.basename(image_path))[0].split('_')[-1])\n",
    "        \n",
    "        image_height = data[\"image_height\"]\n",
    "        image_width = data[\"image_width\"]\n",
    "        \n",
    "        coco_format[\"images\"].append({\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": os.path.basename(image_path),\n",
    "            \"height\": image_height,\n",
    "            \"width\": image_width\n",
    "        })\n",
    "        \n",
    "        for category, annotations in data.items():\n",
    "            if category in category_mapping and annotations:\n",
    "                for bbox in annotations:\n",
    "                    x_min, y_min, x_max, y_max = bbox\n",
    "                    width = x_max - x_min\n",
    "                    height = y_max - y_min\n",
    "\n",
    "                    if width <= 0 or height <= 0:\n",
    "                        print(f\"Invalid box in {json_file}: {bbox}\")\n",
    "                        continue\n",
    "\n",
    "                    coco_format[\"annotations\"].append({\n",
    "                        \"id\": annotation_id,\n",
    "                        \"image_id\": image_id,\n",
    "                        \"category_id\": category_mapping[category],\n",
    "                        \"bbox\": [x_min, y_min, width, height],\n",
    "                        \"area\": width * height,\n",
    "                        \"iscrowd\": 0\n",
    "                    })\n",
    "                    annotation_id += 1\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(coco_format, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T22:27:24.886332Z",
     "iopub.status.busy": "2024-11-24T22:27:24.885960Z",
     "iopub.status.idle": "2024-11-24T22:31:22.729107Z",
     "shell.execute_reply": "2024-11-24T22:31:22.728397Z",
     "shell.execute_reply.started": "2024-11-24T22:27:24.886303Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "json_folder = \"/kaggle/input/own-data-caselab/json/json\"\n",
    "image_folder = \"/kaggle/input/own-data-caselab/image/image\"\n",
    "output_path = \"/kaggle/working/coco_annotations.json\"\n",
    "convert_to_coco_format(json_folder, image_folder, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## определение класса для создания датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T22:31:37.906175Z",
     "iopub.status.busy": "2024-11-24T22:31:37.905816Z",
     "iopub.status.idle": "2024-11-24T22:31:37.915492Z",
     "shell.execute_reply": "2024-11-24T22:31:37.914564Z",
     "shell.execute_reply.started": "2024-11-24T22:31:37.906121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomCocoDataset(Dataset):\n",
    "    def __init__(self, coco_file, image_folder, transforms=None):\n",
    "        self.coco = COCO(coco_file)\n",
    "        self.image_folder = image_folder\n",
    "        self.transforms = transforms\n",
    "        self.image_ids = list(self.coco.imgs.keys())\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image_info = self.coco.loadImgs(image_id)[0]\n",
    "        image = Image.open(os.path.join(self.image_folder, image_info[\"file_name\"])).convert(\"RGB\")\n",
    "        \n",
    "        ann_ids = self.coco.getAnnIds(imgIds=image_id)\n",
    "        annotations = self.coco.loadAnns(ann_ids)\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        masks = []\n",
    "        for ann in annotations:\n",
    "            x_min, y_min, width, height = ann[\"bbox\"]\n",
    "            x_max = x_min + width\n",
    "            y_max = y_min + height\n",
    "    \n",
    "            if width <= 0 or height <= 0:\n",
    "                print(f\"Invalid box {ann['bbox']} in image {image_info['file_name']}\")\n",
    "                continue\n",
    "    \n",
    "            boxes.append([x_min, y_min, x_max, y_max])\n",
    "            labels.append(ann[\"category_id\"])\n",
    "            \n",
    "            mask = Image.new('L', (int(image_info['width']), int(image_info['height'])), 0)\n",
    "            draw = ImageDraw.Draw(mask)\n",
    "            draw.rectangle([x_min, y_min, x_max, y_max], fill=1)\n",
    "            masks.append(np.array(mask))\n",
    "    \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        target = {\n",
    "            \"boxes\": torch.tensor(boxes, dtype=torch.float32),\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.int64),\n",
    "            \"masks\": torch.tensor(masks, dtype=torch.uint8),\n",
    "            \"image_id\": torch.tensor([image_id])\n",
    "        }\n",
    "        return image, target\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## подготовка данных и модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T22:36:15.716504Z",
     "iopub.status.busy": "2024-11-24T22:36:15.716111Z",
     "iopub.status.idle": "2024-11-24T22:36:19.101229Z",
     "shell.execute_reply": "2024-11-24T22:36:19.100375Z",
     "shell.execute_reply.started": "2024-11-24T22:36:15.716473Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transforms = T.Compose([T.ToTensor()])\n",
    "dataset = CustomCocoDataset(output_path, image_folder, transforms)\n",
    "data_loader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T22:33:43.208908Z",
     "iopub.status.busy": "2024-11-24T22:33:43.207978Z",
     "iopub.status.idle": "2024-11-24T22:33:44.724261Z",
     "shell.execute_reply": "2024-11-24T22:33:44.723531Z",
     "shell.execute_reply.started": "2024-11-24T22:33:43.208856Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "backbone = resnet_fpn_backbone('resnet50', pretrained=True)\n",
    "model = MaskRCNN(backbone, num_classes=13) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T22:36:32.909552Z",
     "iopub.status.busy": "2024-11-24T22:36:32.909233Z",
     "iopub.status.idle": "2024-11-24T22:36:32.914569Z",
     "shell.execute_reply": "2024-11-24T22:36:32.913597Z",
     "shell.execute_reply.started": "2024-11-24T22:36:32.909525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T22:42:07.199031Z",
     "iopub.status.busy": "2024-11-24T22:42:07.197885Z",
     "iopub.status.idle": "2024-11-24T22:42:07.215932Z",
     "shell.execute_reply": "2024-11-24T22:42:07.214770Z",
     "shell.execute_reply.started": "2024-11-24T22:42:07.198982Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## цикл обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T22:42:02.322801Z",
     "iopub.status.busy": "2024-11-24T22:42:02.321882Z",
     "iopub.status.idle": "2024-11-24T22:42:02.548547Z",
     "shell.execute_reply": "2024-11-24T22:42:02.547002Z",
     "shell.execute_reply.started": "2024-11-24T22:42:02.322750Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for images, targets in data_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        epoch_loss += losses.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"maskrcnn_custom.pth\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6094981,
     "sourceId": 9927203,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
