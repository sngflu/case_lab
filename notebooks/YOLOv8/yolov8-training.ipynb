{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10001156,"sourceType":"datasetVersion","datasetId":6155973},{"sourceId":178304,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":151908,"modelId":174361}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Устанавливаем и импортируем необходимые библиотеки","metadata":{}},{"cell_type":"code","source":"!pip install ultralytics\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-24T17:15:09.229202Z","iopub.execute_input":"2024-11-24T17:15:09.229697Z","iopub.status.idle":"2024-11-24T17:15:21.138110Z","shell.execute_reply.started":"2024-11-24T17:15:09.229638Z","shell.execute_reply":"2024-11-24T17:15:21.136961Z"},"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport os\nimport shutil\nimport json\nimport tqdm\nfrom ultralytics import YOLO","metadata":{"execution":{"iopub.status.busy":"2024-11-24T17:16:27.460338Z","iopub.execute_input":"2024-11-24T17:16:27.460708Z","iopub.status.idle":"2024-11-24T17:16:32.638414Z","shell.execute_reply.started":"2024-11-24T17:16:27.460675Z","shell.execute_reply":"2024-11-24T17:16:32.637296Z"},"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Подготавливаем данные для модели","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport json\nimport yaml\nimport random\nfrom pathlib import Path\n\n# пути к данным\nSOURCE_IMAGES_DIR = '/kaggle/input/final-dataset/raw_data/images'\nSOURCE_JSONS_DIR = '/kaggle/input/final-dataset/raw_data/jsons'\nOUTPUT_BASE_DIR = '/kaggle/working/custom_data'\n\n# очищаем выходные директории если они существуют\nif os.path.exists(OUTPUT_BASE_DIR):\n    shutil.rmtree(OUTPUT_BASE_DIR)\n\n# создаем необходимые директории\nfor dir_path in [\n    f'{OUTPUT_BASE_DIR}/images/train',\n    f'{OUTPUT_BASE_DIR}/images/val',\n    f'{OUTPUT_BASE_DIR}/labels/train',\n    f'{OUTPUT_BASE_DIR}/labels/val'\n]:\n    os.makedirs(dir_path)\n\n# словарь классов\nclasses = {\n    'title': 0,\n    'paragraph': 1,\n    'table': 2,\n    'picture': 3,\n    'table_signature': 4,\n    'picture_signature': 5,\n    'numbered_list': 6,\n    'marked_list': 7,\n    'header': 8,\n    'footer': 9,\n    'footnote': 10,\n    'formula': 11\n}\n\ndef get_matching_files():\n    \"\"\"\n    Получаем список файлов, у которых есть соответствующие пары json и png\n    \"\"\"\n    image_files = {f.stem for f in Path(SOURCE_IMAGES_DIR).glob('*.png')}\n    json_files = {f.stem for f in Path(SOURCE_JSONS_DIR).glob('*.json')}\n    \n    # находим пересечение множеств - файлы, у которых есть обе версии\n    matching_files = sorted(list(image_files.intersection(json_files)))\n    print(f\"Total images found: {len(image_files)}\")\n    print(f\"Total JSONs found: {len(json_files)}\")\n    print(f\"Matching pairs found: {len(matching_files)}\")\n    return matching_files\n\ndef process_files(file_list, train_ratio=0.8):\n    \"\"\"\n    Обрабатываем файлы, случайно распределяя их между train и val\n    \"\"\"\n    # перемешиваем список файлов\n    random.seed(42)  # для воспроизводимости\n    random.shuffle(file_list)\n    \n    # определяем точку разделения\n    split_point = int(len(file_list) * train_ratio)\n    train_files = file_list[:split_point]\n    val_files = file_list[split_point:]\n    \n    print(f\"\\nSplitting {len(file_list)} files:\")\n    print(f\"Training files: {len(train_files)}\")\n    print(f\"Validation files: {len(val_files)}\")\n    \n    processed_train = 0\n    processed_val = 0\n    \n    # обрабатываем тренировочные и валидационные файлы\n    for is_train, files in [(True, train_files), (False, val_files)]:\n        subset = 'train' if is_train else 'val'\n        \n        for filename in files:\n            try:\n                # копируем изображение\n                src_img = os.path.join(SOURCE_IMAGES_DIR, f'{filename}.png')\n                dst_img = os.path.join(OUTPUT_BASE_DIR, 'images', subset, f'{filename}.png')\n                shutil.copy2(src_img, dst_img)\n                \n                # обрабатываем JSON и создаем YOLO-формат\n                src_json = os.path.join(SOURCE_JSONS_DIR, f'{filename}.json')\n                dst_txt = os.path.join(OUTPUT_BASE_DIR, 'labels', subset, f'{filename}.txt')\n                \n                with open(src_json) as f:\n                    templates = json.loads(f.read())\n                    \n                with open(dst_txt, \"w\") as g:\n                    for name in classes.keys():\n                        if name in templates and len(templates[name]) > 0:\n                            for obj in templates[name]:\n                                # записываем в формате YOLO: class x_center y_center width height\n                                g.write(f\"{classes[name]} {((obj[2] + obj[0]) / 2) / templates['image_width']} \"\n                                      f\"{((obj[3] + obj[1]) / 2) / templates['image_height']} \"\n                                      f\"{(obj[2] - obj[0]) / templates['image_width']} \"\n                                      f\"{(obj[3] - obj[1]) / templates['image_height']}\\n\")\n                \n                if is_train:\n                    processed_train += 1\n                else:\n                    processed_val += 1\n                    \n            except Exception as e:\n                print(f\"Error processing file {filename}: {str(e)}\")\n                continue\n    \n    return processed_train, processed_val\n\ndef create_yaml_config():\n    \"\"\"\n    Создаем конфигурационный YAML файл\n    \"\"\"\n    data = {\n        \"path\": OUTPUT_BASE_DIR,\n        \"train\": 'images/train',\n        \"val\": 'images/val',\n        \"names\": {v: k for k, v in classes.items()}  \n    }\n    \n    config_path = '/kaggle/working/config.yaml'\n    with open(config_path, \"w\") as f:\n        yaml.dump(data, f)\n    return config_path\n\ndef main():\n    # получаем список файлов\n    matching_files = get_matching_files()\n    \n    # обрабатываем файлы\n    processed_train, processed_val = process_files(matching_files)\n    \n    # создаем конфигурацию\n    config_path = create_yaml_config()\n    \n    # выводим финальную статистику\n    print(f\"\\nFinal statistics:\")\n    print(f\"Successfully processed training images: {processed_train}\")\n    print(f\"Successfully processed validation images: {processed_val}\")\n    print(f\"Total processed: {processed_train + processed_val}\")\n    \n    return config_path\n\n# запускаем подготовку данных\nconfig_path = main()","metadata":{"execution":{"iopub.status.busy":"2024-11-24T17:16:51.825135Z","iopub.execute_input":"2024-11-24T17:16:51.825657Z","iopub.status.idle":"2024-11-24T17:20:49.497567Z","shell.execute_reply.started":"2024-11-24T17:16:51.825627Z","shell.execute_reply":"2024-11-24T17:20:49.496613Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Ещё некоторые необходимые импорты","metadata":{}},{"cell_type":"code","source":"!pip install -U ipywidgets\n!pip install -U albumentations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:25:06.443929Z","iopub.execute_input":"2024-11-24T17:25:06.444989Z","iopub.status.idle":"2024-11-24T17:25:25.896370Z","shell.execute_reply.started":"2024-11-24T17:25:06.444929Z","shell.execute_reply":"2024-11-24T17:25:25.895263Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Обучение модели YOLOv8 (предобученной)","metadata":{}},{"cell_type":"code","source":"import torch\nimport os\n\n# очистка памяти и настройка CUDA\ntorch.cuda.empty_cache()\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n\n# загрузка модели\nmodel = YOLO(\"/kaggle/input/yolov8_45epochs_trained/pytorch/default/1/best.pt\")\n\n# обучение\nmodel.train(\n    data=config_path,\n    batch=32,\n    epochs=15,\n    lr0=1e-5,\n    optimizer='AdamW',\n    weight_decay=0.0001,\n    augment=True,\n    degrees=2.0,\n    hsv_h=0.2,\n    hsv_s=0.2,\n    hsv_v=0.2,\n    mosaic=0.0,\n    flipud=0.0,\n    fliplr=0.0,\n    overlap_mask=False,\n    freeze=10\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-24T17:32:46.672246Z","iopub.execute_input":"2024-11-24T17:32:46.672653Z","iopub.status.idle":"2024-11-24T17:56:41.998323Z","shell.execute_reply.started":"2024-11-24T17:32:46.672619Z","shell.execute_reply":"2024-11-24T17:56:41.996771Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Результаты","metadata":{}},{"cell_type":"markdown","source":"Метрики находятся в одной папке с ноутбуком.","metadata":{"execution":{"iopub.status.busy":"2024-11-27T18:37:18.528553Z","iopub.execute_input":"2024-11-27T18:37:18.528979Z","iopub.status.idle":"2024-11-27T18:37:18.567090Z","shell.execute_reply.started":"2024-11-27T18:37:18.528931Z","shell.execute_reply":"2024-11-27T18:37:18.565461Z"}}}]}